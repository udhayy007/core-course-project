{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices: tf.config.experimental.set_memory_growth(device, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, Activation, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#converts input image to ela applied image\n",
    "def convert_to_ela_image(path,quality):\n",
    "\n",
    "    original_image = Image.open(path).convert('RGB')\n",
    "\n",
    "    #resaving input image at the desired quality\n",
    "    resaved_file_name = 'resaved_image.jpg'     #predefined filename for resaved image\n",
    "    original_image.save(resaved_file_name,'JPEG',quality=quality)\n",
    "    resaved_image = Image.open(resaved_file_name)\n",
    "\n",
    "    #pixel difference between original and resaved image\n",
    "    ela_image = ImageChops.difference(original_image,resaved_image)\n",
    "    \n",
    "    #scaling factors are calculated from pixel extremas\n",
    "    extrema = ela_image.getextrema()\n",
    "    max_difference = max([pix[1] for pix in extrema])\n",
    "    if max_difference ==0:\n",
    "        max_difference = 1\n",
    "    scale = 350.0 / max_difference\n",
    "    \n",
    "    #enhancing elaimage to brighten the pixels\n",
    "    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
    "\n",
    "    ela_image.save(\"ela_image.png\")\n",
    "    return ela_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(image_path):\n",
    "    image_size = (128, 128)\n",
    "    return np.array(convert_to_ela_image(image_path, 90).resize(image_size)).flatten() / 255.0         #normalizing the array values obtained from input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # ELA converted images\n",
    "Y = [] # 0 for fake, 1 for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding authentic images\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "# Paths for authentic images in CASIA1 and CASIA2\n",
    "authentic_paths = [\n",
    "    r'C:\\Users\\udhay\\OneDrive\\Documents\\archive\\CASIA1\\Au',  # Authentic images from CASIA1\n",
    "    r'C:\\Users\\udhay\\OneDrive\\Documents\\archive\\CASIA2\\Au'   # Authentic images from CASIA2\n",
    "]\n",
    "\n",
    "# Function to process authentic images\n",
    "for path in authentic_paths:\n",
    "    for filename in tqdm(os.listdir(path), desc=f\"Processing Authentic Images in {path}\"):\n",
    "        if filename.endswith(('jpg', 'png')):\n",
    "            full_path = os.path.join(path, filename)\n",
    "            X.append(prepare_image(full_path))  # Preprocess the image\n",
    "            Y.append(1)  # Label for authentic images (1)\n",
    "\n",
    "print(f'Total authentic images: {len(X)}\\nTotal labels: {len(Y)}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding forged images\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "# Paths for forged images in CASIA1 and CASIA2\n",
    "forged_paths = [\n",
    "    r'C:\\Users\\udhay\\OneDrive\\Documents\\archive\\CASIA1\\Sp',  # Forged images from CASIA1\n",
    "    r'C:\\Users\\udhay\\OneDrive\\Documents\\archive\\CASIA2\\Tp'   # Forged images from CASIA2\n",
    "]\n",
    "\n",
    "# Function to process forged images\n",
    "for path in forged_paths:\n",
    "    for filename in tqdm(os.listdir(path), desc=f\"Processing Forged Images in {path}\"):\n",
    "        if filename.endswith(('jpg', 'png')):\n",
    "            full_path = os.path.join(path, filename)\n",
    "            X.append(prepare_image(full_path))  # Preprocess the image\n",
    "            Y.append(0)  # Label for forged images (0)\n",
    "\n",
    "print(f'Total forged images: {len(X)}\\nTotal labels: {len(Y)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Step 2: Define your prepare_image function (if you haven't already)\n",
    "\n",
    "# Step 3: Load your images and labels into X and Y\n",
    "X = []  # To hold image data\n",
    "Y = []  # To hold labels\n",
    "\n",
    "# Adding authentic images\n",
    "path_authentic = r'C:\\Users\\udhay\\OneDrive\\Documents\\archive\\CASIA1\\Au'  # Path for authentic images\n",
    "for filename in tqdm(os.listdir(path_authentic), desc=\"Processing Authentic Images:\"):\n",
    "    if filename.endswith('jpg') or filename.endswith('png'):\n",
    "        full_path = os.path.join(path_authentic, filename)\n",
    "        X.append(prepare_image(full_path))        \n",
    "        Y.append(1)  # Label for authentic images\n",
    "\n",
    "# Adding forged images\n",
    "path_forged = r'C:\\Users\\udhay\\OneDrive\\Documents\\archive\\CASIA1\\Sp'  # Path for forged images\n",
    "for filename in tqdm(os.listdir(path_forged), desc=\"Processing Forged Images:\"):\n",
    "    if filename.endswith('jpg') or filename.endswith('png'):\n",
    "        full_path = os.path.join(path_forged, filename)\n",
    "        X.append(prepare_image(full_path))        \n",
    "        Y.append(0)  # Label for forged images\n",
    "\n",
    "# Step 4: Convert X and Y to NumPy arrays\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "# Step 5: Reshape X if necessary (based on your model requirements)\n",
    "X = X.reshape(-1, 128, 128, 3)  # Adjust the size according to your image dimensions\n",
    "\n",
    "# Step 6: Partition the dataset into training, validation, and testing\n",
    "X_temp, X_test, Y_temp, Y_test = train_test_split(X, Y, test_size=0.05, random_state=5)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_temp, Y_temp, test_size=0.2, random_state=5)\n",
    "\n",
    "# Print the sizes of the datasets\n",
    "print(f'Training images: {len(X_train)}, Training labels: {len(Y_train)}')\n",
    "print(f'Validation images: {len(X_val)}, Validation labels: {len(Y_val)}')\n",
    "print(f'Test images: {len(X_test)}, Test labels: {len(Y_test)}')\n",
    "\n",
    "# Step 7: Continue with model training and evaluation...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioning dataset for training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume X and Y are already populated with image data and labels\n",
    "\n",
    "# Split the data into training + validation and testing sets\n",
    "X_temp, X_test, Y_temp, Y_test = train_test_split(X, Y, test_size=0.05, random_state=5)\n",
    "\n",
    "# Further split the training + validation into training and validation sets\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_temp, Y_temp, test_size=0.2, random_state=5)\n",
    "\n",
    "# Reshape the data for the model\n",
    "# The following line assumes your images are in the shape (height, width, channels), \n",
    "# where height and width are the dimensions of the images (e.g., 128x128) \n",
    "# and channels is 3 for RGB images. Adjust the dimensions based on your image data.\n",
    "X_train = X_train.reshape(-1, 128, 128, 3)\n",
    "X_val = X_val.reshape(-1, 128, 128, 3)\n",
    "X_test = X_test.reshape(-1, 128, 128, 3)\n",
    "\n",
    "print(f'Training images: {len(X_train)}, Training labels: {len(Y_train)}')\n",
    "print(f'Validation images: {len(X_val)}, Validation labels: {len(Y_val)}')\n",
    "print(f'Test images: {len(X_test)}, Test labels: {len(Y_test)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()  # Sequential Model\n",
    "    model.add(Input(shape=(128, 128, 3)))  # Use Input layer here\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5, 5), padding='valid', activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5, 5), padding='valid', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5, 5), padding='valid', activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5, 5), padding='valid', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5, 5), padding='valid', activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(5, 5), padding='valid', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='valid', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = 15\n",
    "\n",
    "# Learning rate schedule\n",
    "init_lr = 1e-4  # initial learning rate for the optimizer\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate=init_lr,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "\n",
    "# Create the Adam optimizer\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early Stopping\n",
    "early_stopping = EarlyStopping(monitor = 'val_accuracy',\n",
    "                               min_delta = 0,\n",
    "                               patience = 10,\n",
    "                               verbose = 0,\n",
    "                               mode = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(X_train,\n",
    "                 Y_train,\n",
    "                 batch_size = batch_size,\n",
    "                 epochs = epochs,\n",
    "                 validation_data = (X_val, Y_val),\n",
    "                 callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as a .h5 file\n",
    "model.save('model.h5')  # Specify a filename\n",
    "\n",
    "# Get the dictionary containing each metric and the loss for each epoch\n",
    "history_dict = hist.history\n",
    "\n",
    "# Save it as a JSON file\n",
    "with open('history.json', 'w') as f:  # Specify a filename for the JSON file\n",
    "    json.dump(history_dict, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the training and validation curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Figure 1: Loss\n",
    "ax[0].plot(history_dict['loss'], color='b', label=\"Training Loss\")\n",
    "ax[0].plot(history_dict['val_loss'], color='r', label=\"Validation Loss\")\n",
    "ax[0].set_xlabel('Epochs', fontsize=16)\n",
    "ax[0].set_ylabel('Loss', fontsize=16)\n",
    "ax[0].legend(loc='best', shadow=True)\n",
    "ax[0].grid(True)\n",
    "\n",
    "# Figure 2: Accuracy\n",
    "ax[1].plot(history_dict['accuracy'], color='b', label=\"Training Accuracy\")\n",
    "ax[1].plot(history_dict['val_accuracy'], color='r', label=\"Validation Accuracy\")\n",
    "ax[1].set_xlabel('Epochs', fontsize=16)\n",
    "ax[1].set_ylabel('Accuracy', fontsize=16)\n",
    "ax[1].legend(loc='best', shadow=True)\n",
    "ax[1].grid(True)\n",
    "\n",
    "fig.suptitle('Training and Validation Metrics', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cf_matrix):\n",
    "    # Number of images in each classification block\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "    # Percentage value of images in each block with respect to total images\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten() / np.sum(cf_matrix)]\n",
    "\n",
    "    axes_labels = ['Forged', 'Authentic']\n",
    "    # Combine counts and percentages into a label for each block\n",
    "    labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts, group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2, 2)\n",
    "\n",
    "    # Create heatmap\n",
    "    sns.heatmap(cf_matrix, annot=labels, fmt='', cmap=\"flare\", xticklabels=axes_labels, yticklabels=axes_labels)\n",
    "\n",
    "    plt.xlabel('Predicted labels', fontsize=13)\n",
    "    plt.ylabel('True labels', fontsize=13)\n",
    "    plt.title('Confusion Matrix', fontsize=10, fontweight='bold')\n",
    "    plt.show()  # Show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_val)\n",
    "Y_pred_classes = np.round(Y_pred)  # Round off the sigmoid values\n",
    "Y_true = Y_val  # True labels\n",
    "\n",
    "# Compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_true, Y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Forged', 'Authentic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize counters for correct predictions and total test images\n",
    "correct_test = 0  # Correctly predicted test images\n",
    "total_test = len(X_test)  # Total test images\n",
    "\n",
    "# Iterate over the test images and their corresponding labels\n",
    "for index, image in enumerate(tqdm(X_test, desc=\"Processing Images : \")):\n",
    "    image = image.reshape(-1, 128, 128, 3)  # Reshape the image for the model input\n",
    "    y_pred = model.predict(image)  # Get the predicted probabilities\n",
    "    y_pred_class = np.round(y_pred)  # Convert probabilities to binary class (0 or 1)\n",
    "    \n",
    "    # Check if the predicted class matches the true class\n",
    "    if y_pred_class[0][0] == Y_test[index]:  # Use [0][0] to get the scalar value\n",
    "        correct_test += 1\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = correct_test / total_test * 100.0\n",
    "print(f'Total test images: {total_test}')\n",
    "print(f'Correctly predicted images: {correct_test}')\n",
    "print(f'Accuracy: {accuracy:.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing a single image\n",
    "test_image_path = 'path/to/your/test/image.jpg'  # Set your test image path\n",
    "test_image = prepare_image(test_image_path)\n",
    "test_image = test_image.reshape(-1, 128, 128, 3)  # Ensure the shape matches your model's input\n",
    "\n",
    "y_pred = model.predict(test_image)\n",
    "y_pred_class = round(y_pred[0][0])  # Round to get binary class\n",
    "\n",
    "# Displaying the images\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Display original image\n",
    "original_image = plt.imread(test_image_path)\n",
    "ax[0].axis('off')\n",
    "ax[0].imshow(original_image)\n",
    "ax[0].set_title('Original Image')\n",
    "\n",
    "# Display ELA applied image\n",
    "ax[1].axis('off')\n",
    "ax[1].imshow(convert_to_ela_image(test_image_path, 90))\n",
    "ax[1].set_title('ELA Image')\n",
    "\n",
    "# Prediction output\n",
    "print(f'Prediction: {class_names[y_pred_class]}')\n",
    "if y_pred[0][0] <= 0.5:\n",
    "    print(f'Confidence: {(1 - y_pred[0][0]) * 100:0.2f}%')\n",
    "else:\n",
    "    print(f'Confidence: {y_pred[0][0] * 100:0.2f}%')\n",
    "print('--------------------------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder_path = ''  # dataset path\n",
    "authentic, forged, total = 0, 0, 0\n",
    "\n",
    "for filename in tqdm(os.listdir(test_folder_path), desc=\"Processing Images : \"):\n",
    "    if filename.endswith('jpg') or filename.endswith('png'):\n",
    "        test_image_path = os.path.join(test_folder_path, filename)  # use test_folder_path instead of path\n",
    "        test_image = prepare_image(test_image_path)  \n",
    "        test_image = test_image.reshape(-1, 128, 128, 3)  # fix the reshape syntax\n",
    "        y_pred = model.predict(test_image)  # changed from image to test_image\n",
    "        y_pred_class = np.round(y_pred[0][0])  # use y_pred[0][0] to get the predicted class\n",
    "        total += 1\n",
    "        \n",
    "        if y_pred_class == 0:\n",
    "            forged += 1\n",
    "        else:\n",
    "            authentic += 1\n",
    "\n",
    "print(f'Total images: {total}\\nAuthentic Images: {authentic}\\nForged Images: {forged}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
